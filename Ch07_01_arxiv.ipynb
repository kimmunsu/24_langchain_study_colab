{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNWeJyh4jX5z/v+FWBkRlvj",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kimmunsu/24_langchain_study_colab/blob/main/Ch07_01_arxiv.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "LLM 관련 신규 문서들이 Arxiv 를 통해서 많이 발표되고 있고, 해당 내용들을 자동화하고 LLM을 통해 요약하는 로직을 만들기 위해서는 Langchain 에서 만들어놓은 라이브러리를 사용하는게 편합니다.\n",
        "\n",
        "lanchain document : https://python.langchain.com/v0.1/docs/integrations/document_loaders/arxiv/\n",
        "\n",
        "arxiv 라는 것은 Arxiv는 물리학, 수학, 컴퓨터 과학, 정량 생물학, 정량 금융, 통계학, 전기 공학 및 시스템 과학, 경제학 분야의 200만 편의 학술 논문을 위한 오픈 액세스 아카이브입니다.\n",
        "\n",
        "본 실습페이지를 통해서 Arxiv.org에서 과학 논문을 로드하여 다운스트림에서 사용할 수 있는 문서 형식으로 변환하는 방법을 알아봅니다.\n",
        "\n",
        "우선 필요한 패키지들을 설치합니다."
      ],
      "metadata": {
        "id": "frEDYAaC-hwR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install --upgrade langchain\n",
        "\n",
        "# arxiv 라이브러리를 최신 버전으로 업그레이드\n",
        "%pip install -qU arxiv\n",
        "\n",
        "# PDF 파일을 텍스트 형식으로 변환하는 PyMuPDF 파이썬 패키지를 설치\n",
        "%pip install -qU pymupdf"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CddbW3DzJnL1",
        "outputId": "43cedeeb-92cd-44ae-a721-6571cced844f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain in /usr/local/lib/python3.10/dist-packages (0.1.20)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.30)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.9.5)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.3)\n",
            "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.6.6)\n",
            "Requirement already satisfied: langchain-community<0.1,>=0.0.38 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.0.38)\n",
            "Requirement already satisfied: langchain-core<0.2.0,>=0.1.52 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.1.52)\n",
            "Requirement already satisfied: langchain-text-splitters<0.1,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.0.1)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.1.56)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.25.2)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.7.1)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.31.0)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (8.3.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.4)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain) (3.21.2)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain) (0.9.0)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2.0,>=0.1.52->langchain) (1.33)\n",
            "Requirement already satisfied: packaging<24.0,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2.0,>=0.1.52->langchain) (23.2)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.17->langchain) (3.10.3)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.2 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (2.18.2)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (4.11.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2024.2.2)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.3)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.2.0,>=0.1.52->langchain) (2.4)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain) (1.0.0)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m81.1/81.1 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for sgmllib3k (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.5/3.5 MB\u001b[0m \u001b[31m18.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.8/15.8 MB\u001b[0m \u001b[31m31.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "query 로 검색할 키워드를 입력하여 해당 키워드가 포함된 문서의 arxid id 와 제목, 서론, url 정보를 가져와서 json 형태로 return 하는 함수를 구현해봅니다.\n",
        "이때 문서의 양이 방대할 수 있으므로, 문서를 요약까지 이어봅니다."
      ],
      "metadata": {
        "id": "UtHvDrzSPvOJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 설치\n",
        "!pip install -q langchain langchain-google-genai\n",
        "\n",
        "import os\n",
        "from google.colab import userdata\n",
        "os.environ['GOOGLE_API_KEY'] = userdata.get('GOOGLE_API_KEY')"
      ],
      "metadata": {
        "id": "hLJhXMQ6QsFI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!apt install libomp-dev\n",
        "!pip install faiss-cpu"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J_9Hfp5xpM8K",
        "outputId": "0f4ac971-091d-4a37-aa3f-c9aa8049aa4d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "libomp-dev is already the newest version (1:14.0-55~exp2).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 45 not upgraded.\n",
            "Collecting faiss-cpu\n",
            "  Using cached faiss_cpu-1.8.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (27.0 MB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from faiss-cpu) (1.25.2)\n",
            "Installing collected packages: faiss-cpu\n",
            "Successfully installed faiss-cpu-1.8.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import faiss\n",
        "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
        "from langchain.docstore import InMemoryDocstore\n",
        "from langchain.vectorstores import FAISS\n",
        "\n",
        "from langchain.memory import VectorStoreRetrieverMemory\n",
        "\n",
        "# 모델을 정의합니다.\n",
        "embeddings = GoogleGenerativeAIEmbeddings(model=\"models/embedding-001\")\n",
        "\n",
        "# Vector Store 를 초기화 합니다.\n",
        "embedding_size = 1536\n",
        "index = faiss.IndexFlatL2(embedding_size)\n",
        "vectorstore = FAISS(embeddings, index, InMemoryDocstore({}), {})\n",
        "# 벡터 조회가 여전히 의미적으로 관련성 있는 정보를 반환한다는 것을 보여주기 위해서 k 값을 1로 정의합니다.\n",
        "vectorRetriever = vectorstore.as_retriever(search_kwargs={\"k\": 1})\n",
        "memory = VectorStoreRetrieverMemory(retriever=vectorRetriever)"
      ],
      "metadata": {
        "id": "6jrPjshCi4i0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.retrievers import ArxivRetriever\n",
        "import json\n",
        "import pprint\n",
        "\n",
        "retriever = ArxivRetriever()\n",
        "\n",
        "def search_arxiv(query,max_results=10):\n",
        "    res = {\"results\": []}\n",
        "    for result in retriever.arxiv_search(query=query,max_results=max_results).results():\n",
        "        tmp = {\n",
        "            \"arXiv_id\" : result.entry_id.split('abs/')[1][:10],\n",
        "            \"title\": result.title,\n",
        "            \"abstract\": result.summary,\n",
        "            \"url\": result.entry_id}\n",
        "        res[\"results\"].append(tmp)\n",
        "\n",
        "    return json.dumps(res)\n",
        "\n",
        "result = search_arxiv('biogpt', 3) #결과는 최대 3개\n",
        "pprint.pprint(json.loads(result))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9t5UiP9cPuSt",
        "outputId": "46ef95eb-f76c-4067-c5dc-031ebbf70173"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-19-f02582f1270f>:9: DeprecationWarning: The 'Search.results' method is deprecated, use 'Client.results' instead\n",
            "  for result in retriever.arxiv_search(query=query,max_results=max_results).results():\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'results': [{'abstract': 'Pre-trained language models have attracted '\n",
            "                          'increasing attention in the\\n'\n",
            "                          'biomedical domain, inspired by their great success '\n",
            "                          'in the general natural\\n'\n",
            "                          'language domain. Among the two main branches of '\n",
            "                          'pre-trained language models in\\n'\n",
            "                          'the general language domain, i.e., BERT (and its '\n",
            "                          'variants) and GPT (and its\\n'\n",
            "                          'variants), the first one has been extensively '\n",
            "                          'studied in the biomedical domain,\\n'\n",
            "                          'such as BioBERT and PubMedBERT. While they have '\n",
            "                          'achieved great success on a\\n'\n",
            "                          'variety of discriminative downstream biomedical '\n",
            "                          'tasks, the lack of generation\\n'\n",
            "                          'ability constrains their application scope. In this '\n",
            "                          'paper, we propose BioGPT, a\\n'\n",
            "                          'domain-specific generative Transformer language '\n",
            "                          'model pre-trained on large\\n'\n",
            "                          'scale biomedical literature. We evaluate BioGPT on '\n",
            "                          'six biomedical NLP tasks and\\n'\n",
            "                          'demonstrate that our model outperforms previous '\n",
            "                          'models on most tasks.\\n'\n",
            "                          'Especially, we get 44.98%, 38.42% and 40.76% F1 '\n",
            "                          'score on BC5CDR, KD-DTI and DDI\\n'\n",
            "                          'end-to-end relation extraction tasks respectively, '\n",
            "                          'and 78.2% accuracy on\\n'\n",
            "                          'PubMedQA, creating a new record. Our case study on '\n",
            "                          'text generation further\\n'\n",
            "                          'demonstrates the advantage of BioGPT on biomedical '\n",
            "                          'literature to generate\\n'\n",
            "                          'fluent descriptions for biomedical terms. Code is '\n",
            "                          'available at\\n'\n",
            "                          'https://github.com/microsoft/BioGPT.',\n",
            "              'arXiv_id': '2210.10341',\n",
            "              'title': 'BioGPT: Generative Pre-trained Transformer for '\n",
            "                       'Biomedical Text Generation and Mining',\n",
            "              'url': 'http://arxiv.org/abs/2210.10341v3'},\n",
            "             {'abstract': 'The Chief Complaint (CC) is a crucial component of '\n",
            "                          \"a patient's medical record\\n\"\n",
            "                          'as it describes the main reason or concern for '\n",
            "                          'seeking medical care. It\\n'\n",
            "                          'provides critical information for healthcare '\n",
            "                          'providers to make informed\\n'\n",
            "                          'decisions about patient care. However, documenting '\n",
            "                          'CCs can be time-consuming\\n'\n",
            "                          'for healthcare providers, especially in busy '\n",
            "                          'emergency departments. To address\\n'\n",
            "                          'this issue, an autocompletion tool that suggests '\n",
            "                          'accurate and well-formatted\\n'\n",
            "                          'phrases or sentences for clinical notes can be a '\n",
            "                          'valuable resource for triage\\n'\n",
            "                          'nurses. In this study, we utilized text generation '\n",
            "                          'techniques to develop\\n'\n",
            "                          'machine learning models using CC data. In our '\n",
            "                          'proposed work, we train a Long\\n'\n",
            "                          'Short-Term Memory (LSTM) model and fine-tune three '\n",
            "                          'different variants of\\n'\n",
            "                          'Biomedical Generative Pretrained Transformers '\n",
            "                          '(BioGPT), namely\\n'\n",
            "                          'microsoft/biogpt, microsoft/BioGPT-Large, and '\n",
            "                          'microsoft/BioGPT-Large-PubMedQA.\\n'\n",
            "                          'Additionally, we tune a prompt by incorporating '\n",
            "                          'exemplar CC sentences,\\n'\n",
            "                          'utilizing the OpenAI API of GPT-4. We evaluate the '\n",
            "                          \"models' performance based on\\n\"\n",
            "                          'the perplexity score, modified BERTScore, and '\n",
            "                          'cosine similarity score. The\\n'\n",
            "                          'results show that BioGPT-Large exhibits superior '\n",
            "                          'performance compared to the\\n'\n",
            "                          'other models. It consistently achieves a remarkably '\n",
            "                          'low perplexity score of\\n'\n",
            "                          '1.65 when generating CC, whereas the baseline LSTM '\n",
            "                          'model achieves the best\\n'\n",
            "                          'perplexity score of 170. Further, we evaluate and '\n",
            "                          \"assess the proposed models'\\n\"\n",
            "                          'performance and the outcome of GPT-4.0. Our study '\n",
            "                          'demonstrates that utilizing\\n'\n",
            "                          'LLMs such as BioGPT, leads to the development of an '\n",
            "                          'effective autocompletion\\n'\n",
            "                          'tool for generating CC documentation in healthcare '\n",
            "                          'settings.',\n",
            "              'arXiv_id': '2401.06088',\n",
            "              'title': 'Autocompletion of Chief Complaints in the Electronic '\n",
            "                       'Health Records using Large Language Models',\n",
            "              'url': 'http://arxiv.org/abs/2401.06088v1'},\n",
            "             {'abstract': 'Predicting postoperative risk can inform effective '\n",
            "                          'care management &\\n'\n",
            "                          'planning. We explored large language models (LLMs) '\n",
            "                          'in predicting postoperative\\n'\n",
            "                          'risk through clinical texts using various tuning '\n",
            "                          'strategies. Records spanning\\n'\n",
            "                          '84,875 patients from Barnes Jewish Hospital (BJH) '\n",
            "                          'between 2018 & 2021, with a\\n'\n",
            "                          'mean duration of follow-up based on the length of '\n",
            "                          'postoperative ICU stay less\\n'\n",
            "                          'than 7 days, were utilized. Methods were replicated '\n",
            "                          'on the MIMIC-III dataset.\\n'\n",
            "                          'Outcomes included 30-day mortality, pulmonary '\n",
            "                          'embolism (PE) & pneumonia. Three\\n'\n",
            "                          'domain adaptation & finetuning strategies were '\n",
            "                          'implemented for three LLMs\\n'\n",
            "                          '(BioGPT, ClinicalBERT & BioClinicalBERT): '\n",
            "                          'self-supervised objectives;\\n'\n",
            "                          'incorporating labels with semi-supervised '\n",
            "                          'fine-tuning; & foundational modelling\\n'\n",
            "                          'through multi-task learning. Model performance was '\n",
            "                          'compared using the AUROC &\\n'\n",
            "                          'AUPRC for classification tasks & MSE & R2 for '\n",
            "                          'regression tasks. Cohort had a\\n'\n",
            "                          'mean age of 56.9 (sd: 16.8) years; 50.3% male; 74% '\n",
            "                          'White. Pre-trained LLMs\\n'\n",
            "                          'outperformed traditional word embeddings, with '\n",
            "                          'absolute maximal gains of 38.3%\\n'\n",
            "                          'for AUROC & 14% for AUPRC. Adapting models through '\n",
            "                          'self-supervised finetuning\\n'\n",
            "                          'further improved performance by 3.2% for AUROC & '\n",
            "                          '1.5% for AUPRC Incorporating\\n'\n",
            "                          'labels into the finetuning procedure further '\n",
            "                          'boosted performances, with\\n'\n",
            "                          'semi-supervised finetuning improving by 1.8% for '\n",
            "                          'AUROC & 2% for AUPRC &\\n'\n",
            "                          'foundational modelling improving by 3.6% for AUROC '\n",
            "                          '& 2.6% for AUPRC compared to\\n'\n",
            "                          'self-supervised finetuning. Pre-trained clinical '\n",
            "                          'LLMs offer opportunities for\\n'\n",
            "                          'postoperative risk predictions with unseen data, & '\n",
            "                          'further improvements from\\n'\n",
            "                          'finetuning suggests benefits in adapting '\n",
            "                          'pre-trained models to note-specific\\n'\n",
            "                          'perioperative use cases. Incorporating labels can '\n",
            "                          'further boost performance.\\n'\n",
            "                          'The superior performance of foundational models '\n",
            "                          'suggests the potential of\\n'\n",
            "                          'task-agnostic learning towards the generalizable '\n",
            "                          'LLMs in perioperative care.',\n",
            "              'arXiv_id': '2402.17493',\n",
            "              'title': 'Predicting postoperative risks using large language '\n",
            "                       'models',\n",
            "              'url': 'http://arxiv.org/abs/2402.17493v4'}]}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 설치\n",
        "!pip install -q langchain langchain-google-genai\n",
        "\n",
        "import os\n",
        "from google.colab import userdata\n",
        "os.environ['GOOGLE_API_KEY'] = userdata.get('GOOGLE_API_KEY')"
      ],
      "metadata": {
        "id": "tNEnBOeII8Jg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "도큐먼트를 로드하고, 해당 도큐먼트를 번역하고 싶은데, 잘 안되었습니다.. 본 코드를 앞서 arxiv retrieval 과 함께 연결하더라도 마찬가지였습니다.\n",
        "\n",
        "공부를 깊게 안하고 코드부터 대충 되겠지하고 작성했는데, 역시 그럼 늘 안되네요.\n",
        "삽질은 여기까지.."
      ],
      "metadata": {
        "id": "gsEKT8Ophi4S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chains import ConversationalRetrievalChain\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "\n",
        "# ChatGoogleGenerativeAI 언어 모델을 \"gemini-pro\" 모델로 초기화합니다.\n",
        "llm = ChatGoogleGenerativeAI(model=\"gemini-pro\", temperature=0)\n",
        "qa = ConversationalRetrievalChain.from_llm(llm, retriever=retriever)\n",
        "\n",
        "questions = [\n",
        "    \"앞서 ArxivRetriever 에게 질의했던 결과를 모두 한글로 해석해줘\"\n",
        "]\n",
        "chat_history = []\n",
        "\n",
        "for question in questions:\n",
        "    result = qa({\"question\": question, \"chat_history\": chat_history})\n",
        "    chat_history.append((question, result[\"answer\"]))\n",
        "    print(f\"-> **Question**: {question} \\n\")\n",
        "    print(f\"**Answer**: {result['answer']} \\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tuqNAEf0Jt1-",
        "outputId": "546ea21a-e7b3-4f5b-d57d-6452faced579"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-> **Question**: 앞서 ArxivRetriever 에게 질의했던 결과를 모두 한글로 해석해줘 \n",
            "\n",
            "**Answer**: **질의 1:**\n",
            "\n",
            "**원문:** What is the relationship between the number of parameters in a neural network and its generalization performance?\n",
            "\n",
            "**번역:** 신경망의 파라미터 수와 일반화 성능 간의 관계는 무엇입니까?\n",
            "\n",
            "**질의 2:**\n",
            "\n",
            "**원문:** How can we improve the robustness of neural networks to adversarial examples?\n",
            "\n",
            "**번역:** 적대적 예제에 대한 신경망의 견고성을 어떻게 향상시킬 수 있습니까?\n",
            "\n",
            "**질의 3:**\n",
            "\n",
            "**원문:** What are the challenges and opportunities in using deep learning for natural language processing?\n",
            "\n",
            "**번역:** 자연어 처리에 딥러닝을 사용하는 데 있어서 어떤 과제와 기회가 있습니까?\n",
            "\n",
            "**질의 4:**\n",
            "\n",
            "**원문:** How can we use reinforcement learning to solve complex decision-making problems?\n",
            "\n",
            "**번역:** 복잡한 의사 결정 문제를 해결하기 위해 강화 학습을 어떻게 사용할 수 있습니까?\n",
            "\n",
            "**질의 5:**\n",
            "\n",
            "**원문:** What are the ethical implications of using artificial intelligence in society?\n",
            "\n",
            "**번역:** 사회에서 인공 지능을 사용하는 것의 윤리적 의미는 무엇입니까? \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "ArxivLoader는 다음과 같은 인자를 가집니다:\n",
        "\n",
        "query: Arxiv에서 문서를 찾는 데 사용되는 자유 텍스트입니다.\n",
        "\n",
        "load_max_docs(선택): 기본값은 100 입니다. 다운로드할 문서의 수를 제한하는 데 사용합니다. 100개의 문서를 모두 다운로드하는 데는 시간이 걸리므로, 실험을 위해서는 작은 숫자를 사용하도록 합니다.\n",
        "\n",
        "load_all_available_meta(선택): 기본값은 False 로서 true 가 되는 값들만 다운로드합니다. 기본적으로 가장 중요한 필드인 Published, Title, Authors, Summary 등입니다.\n",
        "\n",
        "ArxivLoader를 사용하여 arXiv에서 논문을 로드합니다."
      ],
      "metadata": {
        "id": "egVauPPYKTZg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.document_loaders import ArxivLoader\n",
        "# ArxivLoader를 사용하여 arXiv에서 문서를 로드합니다. query 매개변수는 검색할 논문의 arXiv ID이고, load_max_docs 매개변수는 로드할 최대 문서 수를 지정합니다.\n",
        "docs = ArxivLoader(query=\"1605.08386\", load_max_docs=2).load()\n",
        "len(docs)  # 로드된 문서의 개수를 반환합니다."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RHQrCv1qKxfs",
        "outputId": "d9ba6d17-e8e3-4ada-a13d-a5cc909571a2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "로드된 문서의 수가 결과로 1인 것을 확인하였으니, 배열 index 위치를 활용하여 meta data 를 출력해봅니다."
      ],
      "metadata": {
        "id": "v2Pnx4415YoH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "docs[0].metadata  # 문서의 메타 정보"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p3B3tcHq5pz7",
        "outputId": "1c3693e1-51dc-4572-93c8-76492f57f086"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Published': '2016-05-26',\n",
              " 'Title': 'Heat-bath random walks with Markov bases',\n",
              " 'Authors': 'Caprice Stanley, Tobias Windisch',\n",
              " 'Summary': 'Graphs on lattice points are studied whose edges come from a finite set of\\nallowed moves of arbitrary length. We show that the diameter of these graphs on\\nfibers of a fixed integer matrix can be bounded from above by a constant. We\\nthen study the mixing behaviour of heat-bath random walks on these graphs. We\\nalso state explicit conditions on the set of moves so that the heat-bath random\\nwalk, a generalization of the Glauber dynamics, is an expander in fixed\\ndimension.'}"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    }
  ]
}